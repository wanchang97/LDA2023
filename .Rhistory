op<-par(mfrow=c(1,2))
par(pty='s')
gam.RM<-gam(RM ~ s(LSTAT)+ s(AGE))#,sp=c(40,400))
plot.gam(gam.RM,se=FALSE,rug=FALSE)
par(op)
te.pr.RM<-gam(RM ~ te(LSTAT,AGE, bs="cr"))
summary(te.pr.RM)
#plot(te.pr.RM)
plot(te.pr.RM,theta=20,phi=10,d=1)
plot(te.pr.RM,theta=40,phi=10,d=1)
sd(LSTAT); sd(AGE)
# perspective
vis.gam(te.pr.RM,se=0,theta =40, phi = 10, d=4,nticks=3)
text(-.61,-.1,'RM',srt=90)
# contour
vis.gam(te.pr.RM,se=0,plot.type="contour",contour.col=1)
points(LSTAT,AGE,col="blue")
th.pl.RM1 <- gam(RM ~ s(LSTAT))
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
?s
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
summary(th.pl.RM2)
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
summary(th.pl.RM3)
plot(th.pl.RM1)
plot(th.pl.RM1,redisuals=TRUE)
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
plot(th.pl.RM1,redisuals=TRUE)
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
summary(th.pl.RM2)
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
summary(th.pl.RM3)
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
plot(th.pl.RM1,redisuals=TRUE)
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
summary(th.pl.RM2)
plot(th.pl.RM2,redisuals=TRUE)
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
summary(th.pl.RM3)
plot(th.pl.RM3,redisuals=TRUE)
plot(th.pl.RM1,redisuals=TRUE,shade=TRUE)
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
plot(th.pl.RM1,redisuals=FALSE,shade=TRUE)
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
summary(th.pl.RM2)
plot(th.pl.RM2,redisuals=TRUE)
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
summary(th.pl.RM3)
plot(th.pl.RM3,redisuals=TRUE)
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
plot(th.pl.RM1,redisuals=FALSE,shade=TRUE)
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
summary(th.pl.RM2)
plot(th.pl.RM2,redisuals=TRUE,shade=TRUE)
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
summary(th.pl.RM3)
plot(th.pl.RM3,redisuals=TRUE,shade=TRUE)
th.pl.RM1 <- gam(RM ~ s(LSTAT)) # smoothing spline regression
summary(th.pl.RM1)
plot(th.pl.RM1,residuals=FALSE,shade=TRUE)
th.pl.RM2 <- gam(RM ~ s(LSTAT,bs="cr"))
summary(th.pl.RM2)
plot(th.pl.RM2,residuals=TRUE,shade=TRUE)
th.pl.RM3 <- gam(RM ~ te(LSTAT,bs="cr"))
summary(th.pl.RM3)
plot(th.pl.RM3,residuals=TRUE,shade=TRUE)
library(nlme)
head(Orthodont)
fm1 <- lmList(distance ~ age | Subject, Orthodont)
plot(fm1,resid(.,type="pool")~fitted(.)|Sex,abline=0,id=0.05)
# Learn two stage model for longitudinal data analysis
library(nlme)
# Learn two stage model for longitudinal data analysis
library(nlme)
head(Orthodont)
?Orthodont
summary(Orthodont)
Orthodont.unique <- Orthodont[match( unique(Orthodont$Subject), Orthodont$Subject),]
# For easier interpretation of the results to be shown below, we cna center the age varibale with
Orthodont$age <- Orthodont$age-min(Orthodont$age)
# In this way the model intercepts will reflect the average distance at age 8
# Mixed-Effects Model Approach
# Allowing the intercepts and slopes to (randomly) vary across subjects
# (also sometimes called a random intercepts and slopes model)
res1 <- lme(distance ~age, random=~age|Subject,data =Orthodont)
summary(res1)
# Therefore, the estimated average distance at age 8 is b0 = 22.04 mm (Std.Error SE = .420)
# For each year, the distance is estimated to increase on average by b1 = 0.66 mm (SE = .071)
# However, there is variability in the intercepts and slopes, as reflected by their estimated std(SD(b0i)=1.887 and SD(b1i)=0.226, respectively)
# Also, intercepts and slopes appear to be somewhat correlated (\rho = .21)
# Finally, residual variability remains ( reflecting deviations of the measurements from teh subject-specific regression lines)
# as given by the residual standard deviation of sigma =1.31
data.M01 = Orthodont[c(1:4),]
lm.M01= lm(distance ~age,data.M01)
summary(lm.M01)
data.M16 = Orthodont[Orthodont$Subject=="M16",]
lm.M16= lm(distance ~age,data.M16)
summary(lm.M16)
## Two-stage Approach
# Now let us use a two-stage approach to analyse these data.
# First the linear regression model is fitted to the data for each person separately (i.e., based on the four observations per individual):
fm1 <- lmList(distance ~ age | Subject, Orthodont)
# standardized residuals versus fitted values by gender
plot(fm1, resid(., type = "pool") ~ fitted(.) | Sex, abline = 0, id = 0.05)
# box-plots of residuals by Subject
plot(fm1, Subject ~ resid(.))
# observed versus fitted values by Subject
plot(fm1, distance ~ fitted(.) | Subject, abline = c(0,1))
res.list <- lmList(distance ~ age|Subject,data=Orthodont)
# standardized residuals vs fitted values by gender
plot(res.list,resid(.,type="pool")~fitted(.)|male,abline=0,id=0.05)
# We can examine the individual profiles and fitted regression lines for each individual with
plot(augPred(res.list),grid=TRUE)
res.list <- lmList(distance ~ age|Subject,data=Orthodont)
# We can examine the individual profiles and fitted regression lines for each individual with
plot(augPred(res.list),grid=TRUE)
# From that object, we can extract the estimated model coefficients(intercepts and slopes) and the corresponding variance-covariance matrices with
b = lapply(res.list,coef)  # 54 (27*2) x 1
V = lapply(res.list,vcov)  # 54 x 54
# A dummy variable including the estimate type( alternating intercept and slope) and a subject id variabel are also needed, which can be created with
estm = rep(c("intercept","slope"),length(b))
subj = rep(names(b),each=2)
# Next we create one long vector with the model coefficients and the corresponding block-diagonal variance covariance matrix with ( the metafor package needs to be loded for the bldiag() function):
library(metafor)
b <- unlist(b) # flatten lists
V <- bldiag(V) # construct block diagonal matrix
# Finally we conduct a multivariate meta-analysis with the model coefficients (since we have two correlated coefficients per subject).
# The V matrix contains the variance and covariances of the sampling errors.
# We also allow for heterogeneity in the true outcomes (i.e., coefficients)
# and allow them to be correlated (by using an unstructured variance covariance matrix for the true outcomes)
# The model can be fitted with
# Meta-Analysis via multivariate
res2 = rma.mv(b ~ estm - 1,V,random = ~estm|subj,struct = "UN") # meta-analysis via multivariate linear mixed effects models
res2
# Learn two stage model for longitudinal data analysis
library(nlme)
head(Orthodont)
?Orthodont
summary(Orthodont)
Orthodont.unique <- Orthodont[match( unique(Orthodont$Subject), Orthodont$Subject),]
# For easier interpretation of the results to be shown below, we cna center the age varibale with
Orthodont$age <- Orthodont$age-min(Orthodont$age)
# In this way the model intercepts will reflect the average distance at age 8
# Mixed-Effects Model Approach
# Allowing the intercepts and slopes to (randomly) vary across subjects
# (also sometimes called a random intercepts and slopes model)
res1 <- lme(distance ~age, random=~age|Subject,data =Orthodont)
summary(res1)
# Therefore, the estimated average distance at age 8 is b0 = 22.04 mm (Std.Error SE = .420)
# For each year, the distance is estimated to increase on average by b1 = 0.66 mm (SE = .071)
# However, there is variability in the intercepts and slopes, as reflected by their estimated std(SD(b0i)=1.887 and SD(b1i)=0.226, respectively)
# Also, intercepts and slopes appear to be somewhat correlated (\rho = .21)
# Finally, residual variability remains ( reflecting deviations of the measurements from teh subject-specific regression lines)
# as given by the residual standard deviation of sigma =1.31
data.M01 = Orthodont[c(1:4),]
lm.M01= lm(distance ~age,data.M01)
summary(lm.M01)
data.M16 = Orthodont[Orthodont$Subject=="M16",]
lm.M16= lm(distance ~age,data.M16)
summary(lm.M16)
## Two-stage Approach
# Now let us use a two-stage approach to analyse these data.
# First the linear regression model is fitted to the data for each person separately (i.e., based on the four observations per individual):
# fm1 <- lmList(distance ~ age | Subject, Orthodont)
# # standardized residuals versus fitted values by gender
# plot(fm1, resid(., type = "pool") ~ fitted(.) | Sex, abline = 0, id = 0.05)
# # box-plots of residuals by Subject
# plot(fm1, Subject ~ resid(.))
# # observed versus fitted values by Subject
# plot(fm1, distance ~ fitted(.) | Subject, abline = c(0,1))
res.list <- lmList(distance ~ age|Subject,data=Orthodont)
# We can examine the individual profiles and fitted regression lines for each individual with
plot(augPred(res.list),grid=TRUE)
# From that object, we can extract the estimated model coefficients(intercepts and slopes) and the corresponding variance-covariance matrices with
b = lapply(res.list,coef)  # 54 (27*2) x 1
V = lapply(res.list,vcov)  # 54 x 54
# A dummy variable including the estimate type( alternating intercept and slope) and a subject id variabel are also needed, which can be created with
estm = rep(c("intercept","slope"),length(b))
subj = rep(names(b),each=2)
# Next we create one long vector with the model coefficients and the corresponding block-diagonal variance covariance matrix with ( the metafor package needs to be loded for the bldiag() function):
library(metafor)
b <- unlist(b) # flatten lists
V <- bldiag(V) # construct block diagonal matrix
# Finally we conduct a multivariate meta-analysis with the model coefficients (since we have two correlated coefficients per subject).
# The V matrix contains the variance and covariances of the sampling errors.
# We also allow for heterogeneity in the true outcomes (i.e., coefficients)
# and allow them to be correlated (by using an unstructured variance covariance matrix for the true outcomes)
# The model can be fitted with
# Meta-Analysis via multivariate
res2 = rma.mv(b ~ estm - 1,V,random = ~estm|subj,struct = "UN") # meta-analysis via multivariate linear mixed effects models
res2
#res2.1 = rma.mv(b ~ estm,V,random = ~estm|subj,struct = "UN") # meta-analysis via multivariate linear mixed effects models
#res2.1
setwd("C:/GIthub/LDA2023/LDA2023")
library(readxl)
trenal <- read_excel("Trenal.XLS") # summary(trenal)
trenal= trenal[,-18] #remove a noninformative column const
# Continuous or discrete variables
trenal$id = as.factor(trenal$id)
trenal$j = as.factor(trenal$j)
#trenal$time = as.factor(trenal$time)
trenal$male = as.factor(trenal$male)
trenal$cardio = as.factor(trenal$cardio)
trenal$reject = as.factor(trenal$reject)
# Change the name of respons
colnames(trenal)[19] <- "HC"
trenal.long = trenal[,13:20] # long table form
# Remove j
trenal.long = trenal.long[,-6]
trenal.long.unique <- trenal.long[match( unique(trenal.long$id), trenal.long$id),]
trenal.long.noNA <- na.omit(trenal.long)
# Wide table form
trenal.wide = as.data.frame(subset(trenal,trenal$j=="1"))[,1:18] # 1160 x 18
# Two stage Model analysis
# 1st stage A model for each individual estimating the intercept and time was adjusted
lm.firststage = lm(HC ~ time+age+male+reject+cardio ,trenal.long)
summary(lm.firststage)
trenal.group.age<-groupedData(HC~time|id,trenal.long,outer=~age,labels=list(y="HC level"),units=list(y="(%)"))
trenal.group.male<-groupedData(HC~time|id,trenal.long,outer=~male,labels=list(y="HC level"),units=list(y="(%)"))
trenal.group.reject<-groupedData(HC~time|id,trenal.long,outer=~reject,labels=list(y="HC level"),units=list(y="(%)"))
trenal.group.cardio<-groupedData(HC~time|id,trenal.long,outer=~cardio,labels=list(y="HC level"),units=list(y="(%)"))
list.male<-lmList(HC~time|id,
trenal.group.male, na.action=na.pass)
#View(modlist1)
attributes(list.male)
pdf("intervals.pdf")
plot(intervals(list.male))
dev.off()
beta0<- coef(modlist1)[,1]
beta1<- coef(modlist1)[,2]
beta0<- coef(list.male)[,1]
beta1<- coef(list.male)[,2]
coef(list.male)
bbdd<-data.frame(Id=as.numeric(attributes(list.male)$id),
beta0=coef(list.male)[,1],beta1=coef(list.male)[,2])
res.age <- lme(HC ~ time,random = ~age|Subject,data=trenal.long)
summary(res.age)
library(nlme)
res.age <- lme(HC ~ time,random = ~age|Subject,data=trenal.long)
res.age <- lme(HC ~ time,random = ~age|id,data=trenal.long)
res.age <- lme(HC ~ time,random = ~age|id,data=trenal.long, na.action=na.pass)
res.age <- lme(HC ~ time,random = ~age|id,data=trenal.long, na.action=na.pass)
res.age <- lme(HC ~ time,random = ~age|id,data=trenal.long.noNA, na.action=na.pass)
res.age <- lme(HC ~ time,random = ~age|id,data=trenal.long.noNA)
summary(res.age)
res.list.age <- lmList(HC ~ age | id, data=trenal.long)
res.list.age <- lmList(HC ~ age | id, data=trenal.long.noNA)
plot(augPred(res.list),grid=TRUE)
plot(augPred(res.list.age),grid=TRUE)
set.seed(1)
selected <- sample(1:length(unique(trenal.long.noNA$id)),30,replace=T)
trenal.long.noNA.selected = trenal.long.noNA[(trenal.long.noNA$id %in% c(selected)),]
res.list.age.selected <- lmList(HC ~ age | id, data=trenal.long.noNA.selected)
plot(augPred(res.list.age.selected),grid=TRUE)
## Two-stage Approach
# Now let us use a two-stage approach to analyse these data.
# First the linear regression model is fitted to the data for each person separately (i.e., based on the four observations per individual):
# fm1 <- lmList(distance ~ age | Subject, Orthodont)
# # standardized residuals versus fitted values by gender
# plot(fm1, resid(., type = "pool") ~ fitted(.) | Sex, abline = 0, id = 0.05)
# # box-plots of residuals by Subject
# plot(fm1, Subject ~ resid(.))
# # observed versus fitted values by Subject
# plot(fm1, distance ~ fitted(.) | Subject, abline = c(0,1))
fm1 <- lme(Orthodont)
plot(augPred(fm1, level = 0:1, length.out = 2))
fm1 <- lme(trenal.long.noNA.selected)
plot(augPred(res.age, level = 0:1, length.out = 2))
summary(res.age)
summary(fm1)
plot(augPred(res.age, level = 0:1, length.out = 2))
traceback()
res.male <- lme(HC~time,random=~male|id,data=trenal.long.noNA)
plot(augPred(res.male, level = 0:1, length.out = 2))
res.male <- lme(HC~time,random=~1|id,data=trenal.long.noNA)
plot(augPred(res.male, level = 0:1, length.out = 2))
traceback()
trenal.long.noNA.group <- groupedData(HC ~ time|id,trenal.long.noNA,outer=~male,labels=list(y="HC level",units=list(y="(cm)")))
plot(trenal.long.noNA.group)
trenal.long.noNA.select.groupbymale <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~male,labels=list("HC level", units = list(y="(%)")))
plot(trenal.long.noNA.select.groupbymale)
pdf("GroupedPlot/GroupbyMale")
plot(trenal.long.noNA.select.groupbymale)
dev.off()
pdf("GroupedPlot/GroupbyMale.pdf")
plot(trenal.long.noNA.select.groupbymale)
dev.off()
trenal.long.noNA.select.groupbycardio <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~cardio,labels=list("HC level", units = list(y="(%)")))
pdf("GroupedPlot/GroupbyCardio.pdf")
plot(trenal.long.noNA.select.groupbycardio)
dev.off()
trenal.long.noNA.select.groupbyreject <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~reject,labels=list("HC level", units = list(y="(%)")))
pdf("GroupedPlot/GroupbyReject.pdf")
plot(trenal.long.noNA.select.groupbyreject)
dev.off()
dim(trenal.long.noNA.selected)
selected
head(trenal.long.noNA.select.groupbymale)
head(trenal.long.noNA.selected)
trenal.long.noNA.select.groupbyage <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~age,labels=list("HC level", units = list(y="(%)")))
pdf("GroupedPlot/GroupbyAgee.pdf")
plot(trenal.long.noNA.select.groupbyage)
dev.off()
str(Dyestuff2)
str(Dyestuff)
trenal.long.noNA.select.groupbymale.full <- groupedData(HC ~time+age+male+reject
|id,trenal.long.noNA.selected,outer=~male,labels=list("HC level", units = list(y="(%)")))
trenal.long.noNA.select.groupbymale.full <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~male+reject,labels=list("HC level", units = list(y="(%)")))
trenal.long.noNA.select.groupbymale.full <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~male+reject+age,labels=list("HC level", units = list(y="(%)")))
trenal.long.noNA.select.groupbyfull <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~age+male+reject,labels=list("HC level", units = list(y="(%)")))
trenal.long.noNA.select.groupbyagemalereject <- groupedData(HC ~time|id,trenal.long.noNA.selected,outer=~age+male+reject,labels=list("HC level", units = list(y="(%)")))
plot(trenal.long.noNA.select.groupbyagemalereject)
?groupedData
formula(trenal.long.noNA.select.groupbyagemalereject)
gsummary(trenal.long.noNA.select.groupbyagemalereject)
fm1 <- lme(trenal.long.noNA.select.groupbyagemalereject)
trenal.long.noNA.select.update <- update(trenal.long.noNA.select,FUN=mean)
trenal.long.noNA.select.update <- update(trenal.long.noNA.selected,FUN=mean)
summary(fm1)
gsummary(trenal.long.noNA.select.groupbymale)
gsummary(trenal.long.noNA.select.groupbycardio)
gsummary(trenal.long.noNA.select.groupbyreject)
gsummary(trenal.long.noNA.select.groupbyreject)
gsummary(trenal.long.noNA.select.groupbyagemalereject)
trenal.long.noNA.groupbyage <- groupedData(HC ~ time|id,trenal.long.noNA,outer=~age,labels=list(x = "time",y="HC level",units=list(y="(cm)")))
trenal.long.noNA.groupbymale <- groupedData(HC ~ time|id,trenal.long.noNA,outer=~male,labels=list(x = "time",y="HC level",units=list(y="(cm)")))
trenal.long.noNA.groupbyreject <- groupedData(HC ~ time|id,trenal.long.noNA,outer=~reject,labels=list(x = "time",y="HC level",units=list(y="(cm)")))
trenal.long.noNA.groupbycardio <- groupedData(HC ~ time|id,trenal.long.noNA,outer=~cardio,labels=list(x = "time",y="HC level",units=list(y="(cm)")))
#trenal.long.noNA.select.groupbyagemalerejec
plot(augPred(trenal.long.noNA.select.groupbycardio),grid=TRUE)
plot(augPred(trenal.long.noNA.select.groupbycardio),grid=TRUE)
res.list.groupbyage <- lmList(HC ~ time |id, data=trenal.long.noNA.groupbyage)
b = lapply(res.list.groupbyage,coef)
V = lapply(res.list.groupbyage,vcov)
# First model, no random effects
fit.noRandomEffects <- lme(respons ~ time,data=trenal.long)
# First model, no random effects
fit.noRandomEffects <- lme(HC ~ time,data=trenal.long)
# First model, no random effects
fit.noRandomEffects <- lme(HC ~ time,data=trenal.long.NA)
# First model, no random effects
fit.noRandomEffects <- lme(HC ~ time,data=trenal.long.noNA)
# First model, no random effects
fit.noRandomEffects <- lm(HC ~ time+age+male+reject+cardio,data=trenal.long.noNA)
fit.intercept <- lme(HC~time+age+male+reject+cardio,random=1,data=trenal.long.noNA)
# This is my question on long table and wide table transform:
library(readxl)
trenal <- read_excel("Trenal.XLS") # summary(trenal)
trenal= trenal[,-18] #remove a noninformative column const
# Continuous or discrete variables
trenal$id = as.factor(trenal$id)
trenal$j = as.factor(trenal$j)
trenal$time = as.factor(trenal$time)
trenal$male = as.factor(trenal$male)
trenal$cardio = as.factor(trenal$cardio)
trenal$reject = as.factor(trenal$reject)
# Change the name of respons
colnames(trenal)[19] <- "HC"
trenal.long = trenal[,13:20] # long table form
# Remove j
trenal.long = trenal.long[,-6]
trenal.long.unique <- trenal.long[match( unique(trenal.long$id), trenal.long$id),]
trenal.long.noNA <- na.omit(trenal.long)# reordered
# Wide table form?
trenal.wide = as.data.frame(subset(trenal,trenal$j=="1"))[,1:18] # 1160 x 18
# Analyse the NA values descriptively
## First to collect how many NAs are in HC0, Hc0.5, Hc1, ..., Hc 10
Hc.NA = numeric(12)
for (i in c(1:12)) {
Hc.NA[i] = sum(is.na(trenal.wide[,i]))
}
# 1   0   1  87 205 314 418 508 595 672 749 812
# The number of missing data / the ideal case have all meassurements for everyone
missingdata.percentage = Hc.NA/1160
plot(missingdata.percentage,xaxt="n",xlab ="j",ylab="Missing data%")
axis(side=1,at=c(1,2,3,4,5,6,7,8,9,10,11,12),labels=colnames(trenal.wide)[1:12])
# Conclusion could be at the first three measurements, there are almost full data
# More people tends to miss the measurements when time increases
##Second  We can extract all NA data from the long table to analyse their construction
trenal.long.NA = trenal.long[is.na(trenal.long$HC),]
#t = unique(trenal.long.NA$id) # 821 individuals
trenal.long.NA.unique <- trenal.long.NA[match( unique(trenal.long.NA$id), trenal.long.NA$id),]
summary(trenal.long.NA.unique)
## Conclusion, For the missing data, we can see that
png(file="MissingValueAnalysis.png",
width=600, height=1200)
par(mfrow=c(4,2))
## age
hist(trenal.long.unique$age,title="Age distribution in original data")
hist(trenal.long.NA.unique$age,col="red",title="Age distribution in missing data")
## male
plot(trenal.long.unique$male)
title(main="Gender distribution in original data")
plot(trenal.long.NA.unique$male,col="red")
title(main="Gender distribution in missing data")
## cardio
plot(trenal.long.unique$cardio)
title(main="Cardio distribution in original data")
plot(trenal.long.NA.unique$cardio,col="red")
title(main="Cardio distribution in missing data")
## reject
#hist(as.numeric(trenal.long.NA.unique$reject),freq=FALSE,main="Histogram Plot for reject",xaxt="n")
#axis(side=1,at=c(0,1),labels=c("not reject","reject"))
plot(trenal.long.unique$reject)
title(main="Reject distribution in original data")
plot(trenal.long.NA.unique$reject,col="red")
title(main="Reject distribution in missing data")
dev.off()
hist(trenal.long$HC,title="HC distribution in original data")
# Bivariate summaries
library(ggplot2)
?ggpairs
install.packages("GGally")
# Bivariate summaries
library(ggplot2)
library(GGally)
summary(trenal.long)
gg <- ggpairs(data=trenal.long)
dim(trenal.long)
gg <- ggpairs(data=trenal.long[,2:7])
gg
gg <- ggpairs(data=trenal.long.unique[,2:7])
gg
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE)
library(jtools)
fit.age = lm(HC ~ time +age,data=data.long.noNA)
library(readxl)
trenal <- read_excel("Trenal.XLS") # summary(trenal)
trenal= trenal[,-18] #remove a noninformative column const
# Continuous or discrete variables
trenal$id = as.factor(trenal$id)
trenal$j = as.factor(trenal$j)
trenal$time = as.factor(trenal$time)
trenal$male = as.factor(trenal$male)
trenal$cardio = as.factor(trenal$cardio)
trenal$reject = as.factor(trenal$reject)
# Change the name of respons
colnames(trenal)[19] <- "HC"
trenal.long = trenal[,13:20] # long table form
# Remove j
trenal.long = trenal.long[,-6]
trenal.long.noNA <- na.omit(trenal.long)# reordered
trenal.wide = as.data.frame(subset(trenal,trenal$j=="1"))[,1:18]
summary(trenal.wide)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)
data.long <- trenal.long %>% # reordered long table
relocate(id) %>%
relocate(time,.after = id)%>%
relocate(HC,.after=time)
#summary(data.long)
sum(!is.na(data.long$HC))
data.long.noNA <- na.omit(data.long)# reordered long table without NAs
summary(data.long.noNA)
data_summary_long = data.frame(unclass(summary(data.long.noNA,maxsum=1160)),check.names=FALSE)
data.long.noNA$id[length(data.long.noNA$id)]
library(ggplot2)
# To view the mean structure of the HC for all individuals
ggplot(data.long.noNA,aes(x=as.factor(time),y=HC,group=id))  + geom_line(col="grey")+stat_summary(aes(group=1),geom="line",fun=mean,linewidth=2)+
labs(title="Line plot of HC level for all individuals overtime and the mean structure")
# To view to variance structure
ggplot(data.long.noNA,aes(x=as.factor(time),y=HC))+
geom_boxplot(position=position_dodge(1))+
labs(title="Box Plot of HC level for all indivuduals over time and the variance structure")
HcCorr = trenal.wide[,c(1:12)]
cor(HcCorr,use="complete.obs" ) # also COV for covariance
library("PerformanceAnalytics")
chart.Correlation(HcCorr,historgram=TRUE)
dim(data.long.noNA)
?group_by
library(jtools)
fit.age = lm(HC ~ time +age,data=data.long.noNA)
summ(fit.age)
fit.age = lm(HC ~ time +age,data=data.long.noNA)
summ(fit.age)
data.groupbyage = group_by(data.long.noNA)
data.groupbyage <- data.long.noNA %>%   group_by(age) %>% summarise(avg=mean(HC))
data.groupbyage
plot(data.groupbyage)
library(jtools)
data.groupbyage <- data.long.noNA %>%   group_by(age) %>% summarise(avg=mean(HC))
plot(data.groupbyage,xlab="age",ylab="average HC")
#fit.age = lm(HC ~ time +age,data=data.long.noNA)
#summ(fit.age)
#fit.age = lm(HC ~ time +age,data=data.long.noNA)
#summ(fit.age)
library(jtools)
data.groupbyage <- data.long.noNA %>%   group_by(age) %>% summarise(avgHC=mean(HC))
plot(data.groupbyage,xlab="age",ylab="average HC")
#fit.age = lm(HC ~ time +age,data=data.long.noNA)
#summ(fit.age)
#fit.age = lm(HC ~ time +age,data=data.long.noNA)
#summ(fit.age)
ggplot(data=data.long.noNA,aes(y=HC,x=age))+jitter()
library(ggplot2)
ggplot(data=data.long.noNA,aes(y=HC,x=age))
ggplot(data=data.long.noNA,aes(y=HC,x=age))+geom_point()
ggplot(data=data.long.noNA,aes(y=mean(HC),x=age))+geom_point()
data.groupbyage <- data.long.noNA %>%   group_by(age) %>% summarise(avgHC=mean(HC))
ggplot(data=data.long.noNA,aes(y=avgHC,x=age))+geom_point()
data.groupbyage <- data.long.noNA %>%   group_by(age) %>% summarise(avgHC=mean(HC))
ggplot(data=data.groupbyage,aes(y=avgHC,x=age))+geom_point()
